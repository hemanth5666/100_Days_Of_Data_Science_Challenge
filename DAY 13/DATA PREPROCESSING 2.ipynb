{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71a7688f",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d67f1e",
   "metadata": {},
   "source": [
    "# Categorical encoding"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ee8fcd61",
   "metadata": {},
   "source": [
    "One-Hot encoding (OHE)\n",
    "Ordinal encoding\n",
    "Count and Frequency encoding\n",
    "Target encoding / Mean encoding"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2bb9ab58",
   "metadata": {},
   "source": [
    "It is a commonly used technique for encoding categorical variables. It basically creates binary variables for each category present in the categorical variable. These binary variables will have 0 if it is absent in the category or 1 if it is present. Each new variable is called a dummy variable or binary variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "234174a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "840ce2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Color_Blue  Color_Green  Color_Red\n",
      "0       False        False       True\n",
      "1       False         True      False\n",
      "2        True        False      False\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'Color': ['Red', 'Green', 'Blue']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# One-Hot Encoding\n",
    "one_hot_encoded_df = pd.get_dummies(df, columns=['Color'])\n",
    "print(one_hot_encoded_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56ccee3",
   "metadata": {},
   "source": [
    "# Ordinal Encoding"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6839e488",
   "metadata": {},
   "source": [
    "It simply means a categorical variable whose categories can be ordered and that too meaningfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "601b72ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import *\n",
    "import pandas as pd\n",
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be5d17b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Size\n",
      "0   0.0\n",
      "1   1.0\n",
      "2   2.0\n",
      "['Small', 'Large', 'Medium']\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'Size': ['Small', 'Medium', 'Large']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder(categories=[['Small', 'Medium', 'Large']])\n",
    "df['Size'] = ordinal_encoder.fit_transform(df[['Size']])\n",
    "\n",
    "print(df)\n",
    "inverse_transformed = ordinal_encoder.inverse_transform([[0], [2], [1]])\n",
    "print(list(inverse_transformed.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c66b3e",
   "metadata": {},
   "source": [
    "# Label Encoding"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6417c879",
   "metadata": {},
   "source": [
    "Label encoding assigns a unique integer to each category. This is useful for nominal (unordered) categories. However, it should be used with caution as it can sometimes introduce unintended ordinal relationships between categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "42004a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Animal\n",
      "0       0\n",
      "1       1\n",
      "2       2\n",
      "['Cat', 'Dog', 'Mouse']\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'Animal': ['Cat', 'Dog', 'Mouse']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "df['Animal'] = label_encoder.fit_transform(df['Animal'])\n",
    "\n",
    "print(df)\n",
    "\n",
    "# Inverse Transform\n",
    "inverse_transformed = label_encoder.inverse_transform(df['Animal'])\n",
    "print(list(inverse_transformed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a842bb",
   "metadata": {},
   "source": [
    "# Count and Frequency Encoding"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2d45fab1",
   "metadata": {},
   "source": [
    "Count Encoding replaces each category with the count of its occurrences.Replacement can also be done with the frequency of the percentage of observations in the dataset.Suppose, if 30 of 100 genders are male we can replace male with 30 or by 0.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "96d30d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       City  City_Count  City_Frequency\n",
      "0  New York           2        0.333333\n",
      "1     Paris           3        0.500000\n",
      "2  New York           2        0.333333\n",
      "3    London           1        0.166667\n",
      "4     Paris           3        0.500000\n",
      "5     Paris           3        0.500000\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'City': ['New York', 'Paris', 'New York', 'London', 'Paris', 'Paris']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Count Encoding\n",
    "count_encoding = df['City'].value_counts()\n",
    "df['City_Count'] = df['City'].map(count_encoding)\n",
    "\n",
    "# Frequency Encoding\n",
    "frequency_encoding = df['City'].value_counts(normalize=True)\n",
    "df['City_Frequency'] = df['City'].map(frequency_encoding)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3223d81",
   "metadata": {},
   "source": [
    "# Target / Mean Encoding"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4a2e1215",
   "metadata": {},
   "source": [
    "Target Encoding replaces each category with the mean of the target variable for that category. This is useful when dealing with high cardinality categorical features.But it may cause over-fitting to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3bc579fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       City  Price  City_Target_Encoded\n",
      "0  New York    100           125.000000\n",
      "1     Paris    200           216.666667\n",
      "2  New York    150           125.000000\n",
      "3    London    300           300.000000\n",
      "4     Paris    250           216.666667\n",
      "5     Paris    200           216.666667\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'City': ['New York', 'Paris', 'New York', 'London', 'Paris', 'Paris'],\n",
    "    'Price': [100, 200, 150, 300, 250, 200]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Target Encoding\n",
    "target_mean = df.groupby('City')['Price'].mean()\n",
    "df['City_Target_Encoded'] = df['City'].map(target_mean)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8500c036",
   "metadata": {},
   "source": [
    "# Variable Transformation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "83af5cc1",
   "metadata": {},
   "source": [
    "Machine learning algorithms like linear and logistic regression assume that the variables are normally distributed. If a variable is not normally distributed, sometimes it is possible to find a mathematical transformation so that the transformed variable is Gaussian. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f6ae88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logarithm transformation – log(x)\n",
    "np.log10(data)\n",
    "# Square root transformation – sqrt(x)\n",
    "np.sqrt(data)\n",
    "# Reciprocal transformation – 1 / x\n",
    "1/data\n",
    "# Exponential transformation – exp(x)\n",
    "np.exp(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ad6873",
   "metadata": {},
   "source": [
    "# Discretization"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5e87dd82",
   "metadata": {},
   "source": [
    "Discretization, also known as binning, is the process of transforming continuous data into discrete categories or bins. This can be useful for simplifying data, handling outliers, or preparing data for certain types of models, such as decision trees, which can work better with categorical data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b796ab0c",
   "metadata": {},
   "source": [
    "    Equal Width Binning: Divides the data range into equal-sized intervals.\n",
    "    Equal Frequency Binning: Divides the data so that each bin has the same number of points.\n",
    "    Custom Binning: Allows you to specify custom bin edges.\n",
    "    KBinsDiscretizer: Offers more advanced binning techniques (uniform, quantile, k-means)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644a04a6",
   "metadata": {},
   "source": [
    "# Equal Width Binning\n",
    "\n",
    "This method divides the range of the data into equal-sized intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7b39db62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Value   Binned_Value\n",
      "0      1  (0.961, 14.0]\n",
      "1     10  (0.961, 14.0]\n",
      "2     20   (14.0, 27.0]\n",
      "3     30   (27.0, 40.0]\n",
      "4     40   (27.0, 40.0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'Value': [1, 10, 20, 30, 40]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Equal width binning\n",
    "df['Binned_Value'] = pd.cut(df['Value'], bins=3)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c1113a",
   "metadata": {},
   "source": [
    "# Equal Frequency Binning\n",
    "\n",
    "This method divides the data into bins such that each bin contains the same number of data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "49e6330e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Value      Binned_Value\n",
      "0      1   (0.999, 13.333]\n",
      "1     10   (0.999, 13.333]\n",
      "2     20  (13.333, 26.667]\n",
      "3     30    (26.667, 40.0]\n",
      "4     40    (26.667, 40.0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'Value': [1, 10, 20, 30, 40]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Equal frequency binning\n",
    "df['Binned_Value'] = pd.qcut(df['Value'], q=3)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161c453d",
   "metadata": {},
   "source": [
    "# Custom Binning\n",
    "\n",
    "Custom binning allows you to define your own bin edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4f7a506a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Value Binned_Value\n",
      "0      1      (0, 10]\n",
      "1     10      (0, 10]\n",
      "2     20     (10, 30]\n",
      "3     30     (10, 30]\n",
      "4     40     (30, 40]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'Value': [1, 10, 20, 30, 40]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Custom binning\n",
    "bins = [0, 10, 30, 40]\n",
    "labels = ['(0, 10]', '(10, 30]', '(30, 40]']\n",
    "df['Binned_Value'] = pd.cut(df['Value'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2577d97",
   "metadata": {},
   "source": [
    "# Discretization using KBinsDiscretizer\n",
    "\n",
    "KBinsDiscretizer from sklearn can be used for more advanced binning techniques, such as uniform, quantile, and k-means binning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f3c1f8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Value  Binned_Value\n",
      "0      1           0.0\n",
      "1     10           0.0\n",
      "2     20           1.0\n",
      "3     30           2.0\n",
      "4     40           2.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'Value': [1, 10, 20, 30, 40]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# KBinsDiscretizer\n",
    "kbins = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\n",
    "df['Binned_Value'] = kbins.fit_transform(df[['Value']])\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6055e238",
   "metadata": {},
   "source": [
    "# Types of data\n",
    "\n",
    "Qualitative data - non-numerical data (categorical data)\n",
    "\n",
    "Quantitative data - numerical data\n",
    "\n",
    "## Qualitative data (categorical data)\n",
    "\n",
    "Nominal (eye color) =>(defined categories)\n",
    "\n",
    "Ordinal (high,mid,low) =>(ordered categories)\n",
    "\n",
    "Binary (Yes/No)\n",
    "\n",
    "## Quantitative data\n",
    "\n",
    "### Continuous data\n",
    "(measurements that are rounded =>measured characteristics)\n",
    "\n",
    "\n",
    "Interval (distance between two points is standardized and equal) \n",
    "eg: temperature since it can move below and above 0\n",
    "\n",
    "ratio  (scale starts at 0.0 & all the properties of interval data & true zero)    eg: wight,height\n",
    "\n",
    "\n",
    "Interval data vs. ratio data                                                                               Ratio data gets its name because the ratio of two measurements can be interpreted meaningfully, whereas two measurements cannot be directly compared with intervals.Similarly, 40º is not twice as hot as 20º. Saying uses 0º as a reference point to compare the two temperatures, which is incorrect.\n",
    "\n",
    "### Discrete data \n",
    "(exact values or whole numbers that are not rounded => counted items)\n",
    "\n",
    "Count Data Data representing counts of occurrences or events.\n",
    "\n",
    "Binary data    (0 /1)\n",
    "\n",
    "Nominal data  =>Data where values are discrete and represent categories without inherent order. (1,3,8,2)\n",
    "\n",
    "Ordinal data  Data where values are discrete and represent ordered categories. =>   (1,2,3,4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
